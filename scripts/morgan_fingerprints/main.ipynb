{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "\n",
    "db_params = {\n",
    "    'dbname': os.getenv('DB_NAME'),\n",
    "    'user': os.getenv('DB_USER'),\n",
    "    'password': os.getenv('DB_PASSWORD'),\n",
    "    'host': os.getenv('DB_HOST'),\n",
    "    'port': os.getenv('DB_PORT', '5432')\n",
    "}\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(**db_params)\n",
    "\n",
    "query = (\"SELECT chembl_id, canonical_smiles \"\n",
    "         \"FROM compound_structures \"\n",
    "         \"WHERE canonical_smiles IS NOT NULL;\")\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "\n",
    "def compute_morgan_fingerprint(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        fp = AllChem.GetMorganFingerprint(mol, 2, n_bits=2048)\n",
    "        fp_dict = {int(k): int(v) for k, v in fp.GetNonzeroElements().items()}\n",
    "        return fp_dict\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "batch_size = 100000\n",
    "num_batches = len(df) // batch_size + (1 if len(df) % batch_size > 0 else 0)\n",
    "output_dir = './fingerprints'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for batch_num in range(num_batches):\n",
    "    batch_df = df[batch_num * batch_size:(batch_num + 1) * batch_size]\n",
    "    batch_df['morgan_fingerprint'] = batch_df['canonical_smiles'].apply(\n",
    "        lambda x: compute_morgan_fingerprint(x)\n",
    "    )\n",
    "\n",
    "    batch_df = batch_df.dropna(subset=['morgan_fingerprint'])\n",
    "    \n",
    "    csv_file_path = os.path.join(\n",
    "        output_dir, f\"fingerprints_batch_{batch_num+1}.csv\"\n",
    "    )\n",
    "    batch_df[['chembl_id', 'morgan_fingerprint']].to_csv(\n",
    "        csv_file_path, index=False\n",
    "    )\n",
    "    print(f\"Saved batch {batch_num+1} to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import base64\n",
    "import json\n",
    "\n",
    "# https://stackoverflow.com/questions/72051723/rle-algorithm-in-python\n",
    "def run_length_encode(input_list):\n",
    "    encoding = []\n",
    "    prev_char = input_list[0]\n",
    "    count = 1\n",
    "\n",
    "    for char in input_list[1:]:\n",
    "        if char == prev_char:\n",
    "            count += 1\n",
    "        else:\n",
    "            encoding.append((prev_char, count))\n",
    "            prev_char = char\n",
    "            count = 1\n",
    "    encoding.append((prev_char, count))\n",
    "    return encoding\n",
    "\n",
    "def encode_fingerprint(fingerprint):\n",
    "    rle = run_length_encode(fingerprint)\n",
    "    rle_string = json.dumps(rle)\n",
    "    base64_encoded = base64.b64encode(\n",
    "        rle_string.encode('utf-8')).decode('utf-8'\n",
    "    )\n",
    "    return base64_encoded\n",
    "\n",
    "input_dir = './fingerprints'\n",
    "output_dir = './encoded_fingerprints'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for input_file_name in os.listdir(input_dir):\n",
    "    input_file_path = os.path.join(input_dir, input_file_name)\n",
    "    output_file_path = os.path.join(output_dir, f\"encoded_{input_file_name}\")\n",
    "    \n",
    "    with open(\n",
    "        input_file_path, mode='r'\n",
    "    ) as input_file, open(\n",
    "        output_file_path, mode='w', newline=''\n",
    "    ) as output_file:\n",
    "        \n",
    "        reader = csv.reader(input_file)\n",
    "        writer = csv.writer(output_file)\n",
    "        headers = next(reader)\n",
    "        writer.writerow(headers)\n",
    "        \n",
    "        for row in reader:\n",
    "            chembl_id = row[0]\n",
    "            fingerprint = json.loads(row[1])\n",
    "            encoded_fingerprint = encode_fingerprint(fingerprint)\n",
    "            writer.writerow([chembl_id, encoded_fingerprint])\n",
    "        \n",
    "        print(f\"Encoded fingerprints saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "bucket_name = 'de-school-2024-aws'\n",
    "s3_prefix = 'final_task/valentin_krivolutskii/fingerprints/'\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID', ''),\n",
    "    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY', ''),\n",
    "    region_name=os.getenv('AWS_REGION', '')\n",
    ")\n",
    "\n",
    "\n",
    "def upload_to_s3(file_path, bucket, prefix):\n",
    "    s3.upload_file(\n",
    "        file_path, bucket, os.path.join(prefix, os.path.basename(file_path))\n",
    "    )\n",
    "    print(f\"Uploaded {file_path} to s3://{bucket}/{prefix}\")\n",
    "\n",
    "for file_name in os.listdir(output_dir):\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "    upload_to_s3(file_path, bucket_name, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
